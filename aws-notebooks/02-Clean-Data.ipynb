{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install -Uq pandas==1.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.ticker as mtick\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import sagemaker\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "sns.set_palette(\"Spectral\")\n",
    "size=15\n",
    "params = {'legend.fontsize': 'large',\n",
    "          'figure.figsize': (20,8),\n",
    "          'axes.labelsize': size,\n",
    "          'axes.titlesize': size,\n",
    "          'xtick.labelsize': size*0.75,\n",
    "          'ytick.labelsize': size*0.75,\n",
    "          'axes.titlepad': 25}\n",
    "plt.rcParams.update(params);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to SageMaker Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3client = boto3.client('s3')\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket() \n",
    "folder_prefix = 'opensource-10k-data'\n",
    "print(f\"Default bucket: {bucket}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import credentials saved in a local only file \n",
    "with open('./config.json') as f:\n",
    "    creds = json.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean and Transform Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create company profiles df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [] # an empty list to store the data frames\n",
    "\n",
    "data_dir = 'data/company_profiles'\n",
    "for f in [os.path.join(data_dir, p) for p in os.listdir(data_dir)]:\n",
    "    data = pd.read_json(f) # read data frame from json file\n",
    "    dfs.append(data) # append the data frame to the list\n",
    "\n",
    "company_profiles = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create income sheets df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [] # an empty list to store the data frames\n",
    "\n",
    "data_dir = 'data/income_sheets'\n",
    "for file in [os.path.abspath(os.path.join(data_dir, p)) for p in os.listdir(data_dir) if not p.startswith('.')]:\n",
    "    data = pd.read_json(file) # read data frame from json file\n",
    "    dfs.append(data) # append the data frame to the list\n",
    "\n",
    "income_sheets = pd.concat(dfs, ignore_index=True)\n",
    "income_sheets['fillingDate'] = pd.to_datetime(income_sheets['fillingDate'])\n",
    "income_sheets['year'] = (income_sheets['fillingDate'] - pd.DateOffset(years=1)).dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_sheets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create balance sheets df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [] # an empty list to store the data frames\n",
    "\n",
    "data_dir = 'data/balance_sheets'\n",
    "for file in [os.path.abspath(os.path.join(data_dir, p)) for p in os.listdir(data_dir) if not p.startswith('.')]:\n",
    "    data = pd.read_json(file) # read data frame from json file\n",
    "    dfs.append(data) # append the data frame to the list\n",
    "\n",
    "balance_sheets = pd.concat(dfs, ignore_index=True)\n",
    "balance_sheets['fillingDate'] = pd.to_datetime(balance_sheets['fillingDate'])\n",
    "balance_sheets['year'] = (balance_sheets['fillingDate'] - pd.DateOffset(years=1)).dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balance_sheets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create cash flow df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [] # an empty list to store the data frames\n",
    "\n",
    "data_dir = 'data/cash_flow_statements'\n",
    "for file in [os.path.abspath(os.path.join(data_dir, p)) for p in os.listdir(data_dir) if not p.startswith('.')]:\n",
    "    data = pd.read_json(file) # read data frame from json file\n",
    "    dfs.append(data) # append the data frame to the list\n",
    "\n",
    "cashflow_dataset = pd.concat(dfs, ignore_index=True)\n",
    "cashflow_dataset['fillingDate'] = pd.to_datetime(cashflow_dataset['fillingDate'])\n",
    "cashflow_dataset['year'] = (cashflow_dataset['fillingDate'] - pd.DateOffset(years=1)).dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cashflow_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create main df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = income_sheets[['year','symbol','netIncome','revenue','incomeTaxExpense']]\\\n",
    "        .merge(balance_sheets[['year','symbol','totalStockholdersEquity']], on=['year','symbol'], how='left')\\\n",
    "        .merge(cashflow_dataset[['year','symbol','dividendsPaid','operatingCashFlow',\n",
    "                                 'depreciationAndAmortization','accountsReceivables','accountsPayables',\n",
    "                                 'netCashUsedForInvestingActivites','freeCashFlow'\n",
    "                                ]], on=['year','symbol'], how='left')\n",
    "df = df.rename(columns={\n",
    "    'netIncome':'net_income',\n",
    "    'revenue':'sales',\n",
    "    'totalStockholdersEquity':'book_value',\n",
    "    'incomeTaxExpense':'income_tax',\n",
    "    'accountsReceivables':'net_accounts_receivable',\n",
    "    'accountsPayables':'net_accounts_payable',\n",
    "    'netCashUsedForInvestingActivites':'maintenance_capital_expenditure'\n",
    "})\n",
    "df['book_value_plus_dividends'] = df['book_value'] + df['dividendsPaid']\n",
    "df['year_datetime'] = pd.to_datetime(df['year'].astype(str) + '/12/31', yearfirst=True)\n",
    "df = df.sort_values(by=['symbol','year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the Big Four Growth Rates\n",
    "pg. 131 Invested\n",
    "\n",
    "1. Net Income (Net Profit or Net Earnings)\n",
    "2. Book Value (Equity or Shareholder Equity) + Dividends\n",
    "3. Sales (Revenue)\n",
    "4. Operating Cash\n",
    "\n",
    "Then calculate the growth rate (aka percent change) of each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate 4 Growth Rates\n",
    "df['net_income_growth'] = df.groupby(['symbol'])['net_income'].pct_change()\n",
    "df['book_value_dividends_growth'] = df.groupby(['symbol'])['book_value_plus_dividends'].pct_change()\n",
    "df['sales_growth'] = df.groupby(['symbol'])['sales'].pct_change()\n",
    "df['cash_flow_growth'] = df.groupby(['symbol'])['operatingCashFlow'].pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize growth rates over time\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(nrows=2, ncols=2, sharey=False, figsize=(15,8))\n",
    "\n",
    "sns.lineplot(data=df, x='year_datetime', y='net_income_growth', hue='symbol', ax=ax1)\n",
    "sns.lineplot(data=df, x='year_datetime', y='book_value_dividends_growth', hue='symbol', ax=ax2)\n",
    "sns.lineplot(data=df, x='year_datetime', y='sales_growth', hue='symbol', ax=ax3)\n",
    "sns.lineplot(data=df, x='year_datetime', y='cash_flow_growth', hue='symbol', ax=ax4)\n",
    "\n",
    "# Define the date format\n",
    "date_form = mdates.DateFormatter(\"%Y\")\n",
    "for ax in [ax1, ax2, ax3, ax4]:\n",
    "    ax.yaxis.set_major_formatter(mtick.PercentFormatter(xmax=1.0))\n",
    "    ax.xaxis.set_major_locator(mdates.YearLocator(base=1, month=12, day=31))\n",
    "    ax.xaxis.set_major_formatter(date_form)\n",
    "    ax.set_xlabel('year', fontsize=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the Windage Growth Rate\n",
    "or the one growth rate to use for subsequent analysis\n",
    "\n",
    "pg. 133 Invested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare across growth rates\n",
    "growth_rates = \\\n",
    "df.groupby('symbol').agg({'net_income_growth':['mean','std','median'],\n",
    "                          'book_value_dividends_growth':['mean','std','median'],\n",
    "                          'sales_growth':['mean','std','median'],\n",
    "                          'cash_flow_growth':['mean','std','median']\n",
    "                         })\n",
    "\n",
    "# Calculate the overall growth rate we'll use in analysis as an average between our mean and medians for past several years\n",
    "# and use only 90% of that windage estimate and round down to the nearest ones/single digit percentage (being conservative in our estimate for growth)\n",
    "growth_rates['windage_growth_rate'] = \\\n",
    "growth_rates[[('net_income_growth', 'mean'),('net_income_growth', 'median'),\n",
    "              ('book_value_dividends_growth', 'mean'),('book_value_dividends_growth', 'median'),\n",
    "              ('sales_growth', 'mean'),('sales_growth', 'median'),\n",
    "              ('cash_flow_growth','mean'), ('cash_flow_growth', 'median')\n",
    "             ]].mean(axis=1).round(decimals=2)*0.90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "growth_rates.sort_values(by=['windage_growth_rate'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*^ Do these windage growth rates look reasonable? How do they compare with analysts' forecasts?*\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Valuations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Owners Earnings for Ten Cap\n",
    "pg. 194 Invested  \n",
    "\n",
    "Net Income   \n",
    "\\+ Depreciation & Amortization   \n",
    "\\+ Net Change in Accounts Receivables   \n",
    "\\+ Net Change in Accounts Payable   \n",
    "\\+ Income Tax   \n",
    "\\+ Maintainance Capital Expenditures  \n",
    "= Owner Earnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def owner_earnings_cap(row, cap=10):\n",
    "    return (row['net_income'] \\\n",
    "         + row['depreciationAndAmortization'] \\\n",
    "         + row['net_accounts_receivable'] \\\n",
    "         + row['net_accounts_payable'] \\\n",
    "         + row['income_tax'] \\\n",
    "         + row['maintenance_capital_expenditure']) * cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['owner_earnings_ten_cap'] = df.apply(lambda row: owner_earnings_cap(row, 10), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.reset_index().groupby(['symbol'])['year'].idxmin()][['year','symbol','owner_earnings_ten_cap']].sort_values(by='owner_earnings_ten_cap', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Payback Time\n",
    "pg. 201 Invested\n",
    "\n",
    "Free Cash Flow grown by the compunded Windage Growth Rate for 8 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "free_cash_flow = df.loc[df.reset_index().groupby(['symbol'])['year'].idxmin()][['year','symbol','freeCashFlow']]\n",
    "free_cash_flow = free_cash_flow.merge(growth_rates[['windage_growth_rate']].reset_index(), on='symbol').rename(columns={('windage_growth_rate',''): 'windage_growth_rate'}).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeCashFlow_analysis(year_0_free_cash_flow, windage_growth_rate):\n",
    "    free_cash_flow = [year_0_free_cash_flow]\n",
    "    expected_growth_in_freeCashFlow = []\n",
    "    cumu_free_cash_flow = [0]\n",
    "    \n",
    "    # payback time in 8 years (+1 for year 0)\n",
    "    for year in range(9):\n",
    "        new_growth_in_cash_flow = free_cash_flow[-1] * windage_growth_rate\n",
    "\n",
    "        expected_growth_in_freeCashFlow.append(new_growth_in_cash_flow)\n",
    "        free_cash_flow.append(free_cash_flow[-1] + new_growth_in_cash_flow)\n",
    "        cumu_free_cash_flow.append(cumu_free_cash_flow[-1] + free_cash_flow[-1])\n",
    "        \n",
    "    return free_cash_flow[:-1], expected_growth_in_freeCashFlow, cumu_free_cash_flow[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "free_cash_flow_analysis_dfs = []\n",
    "\n",
    "for symbol in free_cash_flow['symbol'].values:\n",
    "    symbol_df = free_cash_flow.loc[free_cash_flow['symbol']==symbol]\n",
    "    \n",
    "    free_cash_flow_lst, \\\n",
    "    expected_growth_in_freeCashFlow_lst, \\\n",
    "    cumu_free_cash_flow_lst = freeCashFlow_analysis(symbol_df['freeCashFlow'].item(), symbol_df['windage_growth_rate'].item())\n",
    "    year = symbol_df['year'].item()\n",
    "                 \n",
    "    symbol_df = pd.DataFrame({'free_cash_flow':free_cash_flow_lst,\n",
    "                      'expected_growth_in_freeCashFlow':expected_growth_in_freeCashFlow_lst,\n",
    "                      'cumu_free_cash_flow':cumu_free_cash_flow_lst,\n",
    "                      'year': range(year, year+9)\n",
    "                      })\n",
    "    symbol_df['symbol'] = symbol\n",
    "    \n",
    "    free_cash_flow_analysis_dfs.append(symbol_df)\n",
    "    \n",
    "\n",
    "free_cash_flow_analysis = pd.concat(free_cash_flow_analysis_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = free_cash_flow_analysis.groupby(['symbol'])['year'].transform(max) == free_cash_flow_analysis['year']\n",
    "free_cash_flow_analysis[idx][['symbol','year','cumu_free_cash_flow']].sort_values(by='cumu_free_cash_flow', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
